{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9e0aa60-37c0-4bd0-a3c8-954c5acac001",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Transformer\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ca3487a2-1b73-4073-883f-73901d8071e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cpu' #torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "x = torch.tensor([\n",
    "            [1, 5, 6, 4, 3, 9, 5, 2, 0],\n",
    "            [1, 8, 7, 3, 4, 5, 6, 7, 2]\n",
    "                ]).to(device)\n",
    "\n",
    "x0 = torch.tensor([\n",
    "            [0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "            [1, 8, 7, 3, 4, 5, 6, 7, 2]\n",
    "                ]).to(device)\n",
    "trg = torch.tensor([\n",
    "            [1, 7, 4, 3, 5, 9, 2, 0],\n",
    "            [1, 5, 6, 2, 4, 7, 6, 2]\n",
    "                ]).to(device)\n",
    "\n",
    "src_pad_idx = 0\n",
    "trg_pad_idx = 0\n",
    "src_vocab_size = 10\n",
    "trg_vocab_size = 10\n",
    "\n",
    "model = Transformer(\n",
    "        src_vocab_size,\n",
    "        trg_vocab_size,\n",
    "        src_pad_idx,\n",
    "        trg_pad_idx,\n",
    "        device=device\n",
    "                    ).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "518b998a-7bb8-4300-bbc8-895e81aee5b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 9])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "6e2cbcfd-ddaa-4dd6-b5d8-298ccf5d7761",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1, 7, 4, 3, 5, 9, 2],\n",
       "         [1, 5, 6, 2, 4, 7, 6]]),\n",
       " torch.Size([2, 7]),\n",
       " torch.Size([2, 8]))"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trg[:, :-1], trg[:, :-1].shape, trg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "1cd55dae-e64d-44d1-9d2f-234dccf25a77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.3299, -0.9455, -0.4432, -1.1032, -0.0143,  0.0863, -0.5562, -0.5071,\n",
       "          0.0025,  0.3875],\n",
       "        [-0.2193,  0.1459,  0.0578, -1.0030,  0.1935,  0.1004, -0.2461, -0.6875,\n",
       "          0.3093,  0.6319],\n",
       "        [-0.4411, -0.4814, -0.7593, -0.8522,  0.0884,  0.9218, -0.8620, -0.6481,\n",
       "          0.4670, -0.4856],\n",
       "        [-1.0341, -0.3689,  0.1061,  0.2436,  0.5519, -0.2100, -0.8712,  0.0567,\n",
       "         -0.3093,  1.1816],\n",
       "        [-0.4440, -0.8197, -0.2595, -0.5893, -0.0886,  0.1281, -0.9936, -1.8873,\n",
       "          0.1936, -0.9485],\n",
       "        [-0.9687,  0.3648, -0.6937, -0.0388, -0.3577, -0.3664, -1.4643, -0.3819,\n",
       "          1.2589,  0.2598],\n",
       "        [ 0.2474, -0.2774, -1.2459, -0.8634, -0.3968, -0.0247, -0.9729, -0.5809,\n",
       "          0.2782,  0.4028]], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(x[:, :-2], trg[:, :-1])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "761a1f5c-e8b7-4c0e-8bec-d9d2b7aa3290",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.3567, -0.5561, -0.6778, -1.1785, -0.1347,  0.2910, -0.9880, -0.0993,\n",
       "         -0.5660,  0.1328],\n",
       "        [ 0.3511,  0.4719, -0.2511, -1.0957,  0.0651,  0.4783, -0.6951, -0.4522,\n",
       "         -0.3153,  0.3716],\n",
       "        [ 0.3098, -0.0091, -0.8179, -0.9697, -0.0577,  1.0629, -1.1236, -0.3785,\n",
       "         -0.3261, -0.6616],\n",
       "        [-0.3216, -0.0347, -0.1215,  0.1859,  0.3932,  0.1305, -1.2242,  0.2934,\n",
       "         -1.0580,  0.8651],\n",
       "        [ 0.2365, -0.2893, -0.5983, -0.6762, -0.0602,  0.3839, -1.5148, -1.4460,\n",
       "         -0.3303, -1.0405],\n",
       "        [-0.2012,  0.6639, -1.0010, -0.2271, -0.3721,  0.0323, -1.9351, -0.1304,\n",
       "          0.5268,  0.0940]], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(x0[:, :-2], trg[:, :-2])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "eed2133e-732e-4f1d-b724-7e70bc75e9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = model.train(mode=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4556ee62-2030-4103-80f3-2b20b6a04e36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'training': False,\n",
       " '_parameters': OrderedDict(),\n",
       " '_buffers': OrderedDict(),\n",
       " '_non_persistent_buffers_set': set(),\n",
       " '_backward_pre_hooks': OrderedDict(),\n",
       " '_backward_hooks': OrderedDict(),\n",
       " '_is_full_backward_hook': None,\n",
       " '_forward_hooks': OrderedDict(),\n",
       " '_forward_hooks_with_kwargs': OrderedDict(),\n",
       " '_forward_hooks_always_called': OrderedDict(),\n",
       " '_forward_pre_hooks': OrderedDict(),\n",
       " '_forward_pre_hooks_with_kwargs': OrderedDict(),\n",
       " '_state_dict_hooks': OrderedDict(),\n",
       " '_state_dict_pre_hooks': OrderedDict(),\n",
       " '_load_state_dict_pre_hooks': OrderedDict(),\n",
       " '_load_state_dict_post_hooks': OrderedDict(),\n",
       " '_modules': OrderedDict([('encoder',\n",
       "               Encoder(\n",
       "                 (word_embedding): Embedding(100, 256)\n",
       "                 (position_embedding): Embedding(100, 256)\n",
       "                 (layers): ModuleList(\n",
       "                   (0-5): 6 x TransformerBlock(\n",
       "                     (attention): SelfAttention(\n",
       "                       (values): Linear(in_features=32, out_features=32, bias=False)\n",
       "                       (keys): Linear(in_features=32, out_features=32, bias=False)\n",
       "                       (queries): Linear(in_features=32, out_features=32, bias=False)\n",
       "                       (fc_out): Linear(in_features=256, out_features=256, bias=True)\n",
       "                     )\n",
       "                     (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "                     (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "                     (feed_forward): Sequential(\n",
       "                       (0): Linear(in_features=256, out_features=1024, bias=True)\n",
       "                       (1): ReLU()\n",
       "                       (2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "                     )\n",
       "                     (dropout): Dropout(p=0, inplace=False)\n",
       "                   )\n",
       "                 )\n",
       "                 (dropout): Dropout(p=0, inplace=False)\n",
       "               )),\n",
       "              ('decoder',\n",
       "               Decoder(\n",
       "                 (word_embedding): Embedding(10, 256)\n",
       "                 (position_embedding): Embedding(100, 256)\n",
       "                 (layers): ModuleList(\n",
       "                   (0-5): 6 x DecoderBlock(\n",
       "                     (attention): SelfAttention(\n",
       "                       (values): Linear(in_features=32, out_features=32, bias=False)\n",
       "                       (keys): Linear(in_features=32, out_features=32, bias=False)\n",
       "                       (queries): Linear(in_features=32, out_features=32, bias=False)\n",
       "                       (fc_out): Linear(in_features=256, out_features=256, bias=True)\n",
       "                     )\n",
       "                     (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "                     (transformer_block): TransformerBlock(\n",
       "                       (attention): SelfAttention(\n",
       "                         (values): Linear(in_features=32, out_features=32, bias=False)\n",
       "                         (keys): Linear(in_features=32, out_features=32, bias=False)\n",
       "                         (queries): Linear(in_features=32, out_features=32, bias=False)\n",
       "                         (fc_out): Linear(in_features=256, out_features=256, bias=True)\n",
       "                       )\n",
       "                       (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "                       (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "                       (feed_forward): Sequential(\n",
       "                         (0): Linear(in_features=256, out_features=1024, bias=True)\n",
       "                         (1): ReLU()\n",
       "                         (2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "                       )\n",
       "                       (dropout): Dropout(p=0, inplace=False)\n",
       "                     )\n",
       "                     (dropout): Dropout(p=0, inplace=False)\n",
       "                   )\n",
       "                 )\n",
       "                 (fc_out): Linear(in_features=256, out_features=10, bias=True)\n",
       "                 (dropout): Dropout(p=0, inplace=False)\n",
       "               ))]),\n",
       " 'src_pad_idx': 0,\n",
       " 'trg_pad_idx': 0,\n",
       " 'device': 'cpu'}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5bcb9dee-5c44-4142-bb83-a53da1e8f7b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 1.0239,  0.4032,  0.4141, -0.5993, -0.1736, -0.2945,  0.3026,\n",
      "          -0.2899, -0.1778, -0.4827],\n",
      "         [ 0.3920, -0.0982, -0.2291,  0.5510,  0.2726,  0.7251,  0.5545,\n",
      "           0.2318, -0.1314, -0.6601],\n",
      "         [ 0.1243, -0.2480,  0.2311, -0.7781,  0.0332,  0.2505,  0.6322,\n",
      "           1.2396, -0.0157, -0.6503],\n",
      "         [ 0.2661, -0.6432, -0.2973, -0.7532, -0.3159, -0.0192, -0.0825,\n",
      "           0.4322,  0.0517, -0.6020],\n",
      "         [ 0.6415, -0.1725,  0.4561, -0.3545, -0.2782,  0.0218, -1.0065,\n",
      "           0.0048,  0.1238, -0.3268],\n",
      "         [ 0.1579, -0.5693,  0.4820, -0.3092, -0.3181,  0.1356, -0.2002,\n",
      "           1.2272,  0.6198, -1.0544],\n",
      "         [ 1.1024,  0.0890,  0.6984, -0.1608,  0.3280,  0.2453,  0.2567,\n",
      "           0.3979,  0.5171, -0.1645]],\n",
      "\n",
      "        [[ 1.0027,  0.4580,  0.4955, -0.4880, -0.2184, -0.4111,  0.2063,\n",
      "          -0.5721, -0.1969, -0.5896],\n",
      "         [ 0.7461, -0.3191,  0.1018, -0.1082, -0.4229,  1.2341,  0.1967,\n",
      "           0.2269, -0.5271, -0.6328],\n",
      "         [-0.0891, -0.5635,  0.6583, -0.6163, -0.5071,  0.1224,  0.0439,\n",
      "          -0.3101,  0.1024, -0.0936],\n",
      "         [ 0.8125, -0.2794,  0.5274, -0.4438, -0.1515,  0.0821,  0.8345,\n",
      "          -0.1650,  0.2284, -0.4531],\n",
      "         [ 0.3809, -0.1806,  0.6240,  0.0084,  0.0739, -0.3582, -0.4045,\n",
      "           0.4835, -0.2571, -0.8682],\n",
      "         [ 0.2632, -0.3519,  0.4027,  0.2065,  0.5044,  0.0399, -0.0188,\n",
      "           0.1286,  0.0874, -0.8078],\n",
      "         [ 0.5112, -0.5863,  1.2653, -0.2626, -0.3419,  0.1260, -0.6406,\n",
      "           0.1282, -0.0070, -0.1588]]], grad_fn=<ViewBackward0>)\n",
      "torch.Size([2, 7, 10])\n"
     ]
    }
   ],
   "source": [
    "out = model(x[:, :-2], trg[:, :-1])\n",
    "print(out)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b7fb1a-ba6f-45cd-89dd-0a519ff2935a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".neuro",
   "language": "python",
   "name": ".neuro"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
